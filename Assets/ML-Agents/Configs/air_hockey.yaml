behaviors:
  AirHockeyBrain:
    trainer_type: ppo
    hyperparameters:
      batch_size:   1024
      buffer_size:  10240
      learning_rate: 3.0e-4
      beta:         5.0e-3
      epsilon:      0.2
      lambd:        0.95
      num_epoch:    3
    network_settings:
      normalize:    true
      hidden_units: 512
      num_layers:   6
    reward_signals:
      extrinsic:
        gamma:      0.99
        strength:   1.0
    max_steps:     1e8         # total number of environment steps
    time_horizon:  100000         # how many steps to collect before learning
    summary_freq:  10000       # how often (in steps) to write TensorBoard stats
